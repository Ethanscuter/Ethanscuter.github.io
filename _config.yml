exclude: ['README.md']
timezone: US/Eastern
papers:
  - layout: paper
    year: 2019
    paper-type: inproceedings
    img: IJWSR2017
    title: Fusing External Language Model in Abstractive Summarization.
    authors: <span class="color-blue">Xintong Wang</span>,Wenjie Li
    booktitle: "Preprint"
    booktitle-url: papers/Fusion.pdf
    doc-url: papers/Fusion.pdf
    venue: workshop
    abstract: >
        Recent sequence-to-sequence neural network models provide a viable new solution to abstractive text summarization, which aims to rewrite a long text into a short and concise form while preserving the most crucial information. However, these models face significant challenges when generating both semantically and syntactically correct summaries. In this work, we explore the potential approaches to incorporate an external (pre-trained) language model to augment the linguistic quality of text generation. This allows the internal (decoder) language model to focus more on jointly learning summary content selection and generation. Fused with the external language model, our abstractive summarization model achieves the results comparable to state-of-the-art models in terms of ROUGE scores, and meanwhile shows significant improvements in both perplexity and human evaluations. 
  - layout: paper
    year: 2020
    paper-type: inproceedings
    img: IJWSR2017
    title: Plausibility-promoting Generative Adversarial Network for Abstractive Text Summarization with Multi-task Constraint.
    authors: <span class="color-blue">Xintong Wang</span>, Min Yang, Yao Lu, Jianming Lv, Ying Shen, Chengming Li
    booktitle: "Information Science (Q1 Journal)"
    booktitle-url: papers/AGANABS.pdf
    doc-url: papers/AGANABS.pdf
    venue: workshop
    abstract: >
        Recent artificial intelligence studies have witnessed great interests in generating condensed and concise summaries automatically that retain the salient information of a source text, which is known as the abstractive text summarization task. In this paper, we present a Generative Adversarial Network for Abstractive Text Summarization with Multi-Task constraint (GAN-ATSMT). Specifically, GANATSMT utilizes an adversarial framework to jointly train a generative model G and a discriminative model D. The generative model G employs the sequence-to-sequence architecture as its backbone, taking the original text as input and generate the summary. We employ a convolutional neural network (CNN) classifier as the discriminative model D, which attempts to distinguish the generated summaries from the ground truth summaries. The generator G and the discriminator D are optimized with a minimax two-player game. Thus, this adversarial process can eventually adjust G to generate plausible and high-quality summaries. Furthermore, we additionally propose extended regularizations for the generative model G using the multi-task learning, sharing its LSTM encoder and LSTM decoder with the text categorization task and the syntax annotation task, respectively. The auxiliary tasks help to improve the quality of locating salient information of a document and generate high-quality summaries from language modeling perspective alleviating the issues of incomplete sentences and duplicated words. We conduct extensive experiments to estimate the effectiveness of GAN-ATSMT model on two real-life datasets. Experimental results illustrate that GAN-ATSMT is able to achieve better performance than the state-of-the-art abstractive text summarization methods in terms of the quantitative evaluation metrics (i.e., ROUGE and human evaluation) and qualitative evaluation.
  - layout: paper
    year: 2018
    paper-type: inproceedings
    img: IJWSR2017
    title: Cross-dataset Person Re-Identification Using Similarity Preserved Generative Adversarial Networks.
    authors: <span class="color-blue">Xintong Wang</span>, Jianming Lv
    booktitle: "Proceedings of the 11th International Conference on Knowledge Science, Engineering and Management <strong>KSEM</strong>, (CCF-C Conference)"
    booktitle-url: papers/1806.04533.pdf
    doc-url: papers/Lv-Wang2018_Chapter_Cross-DatasetPersonRe-identifi.pdf
    venue: workshop
    abstract: >
        Person re-identification (Re-ID) aims to match the image frames which contain the same person in the surveillance videos. Most of the Re-ID algorithms conduct supervised training in some small labeled datasets, so directly deploying these trained models to the real-world large camera networks may lead to a poor performance due to underfitting. The significant difference between the source training dataset and the target testing dataset makes it challenging to incrementally optimize the model. To address this challenge, we propose a novel solution by transforming the unlabeled images in the target domain to fit the original classifier by using our proposed similarity preserved generative adversarial networks model, SimPGAN. Specifically, SimPGAN adopts the generative adversarial networks with the cycle consistency constraint to transform the unlabeled images in the target domain to the style of the source domain. Meanwhile, SimPGAN uses the similarity consistency loss, which is measured by a siamese deep convolutional neural network, to preserve the similarity of the transformed images of the same person. Comprehensive experiments based on multiple real surveillance datasets are conducted, and the results show that our algorithm is better than the state-of-the-art cross-dataset unsupervised person Re-ID algorithms.
