exclude: ['README.md']
timezone: US/Eastern
papers:
  - layout: paper
    year: 2018
    paper-type: inproceedings
    img: IJWSR2017
    title: Cross-dataset Person Re-Identification Using Similarity Preserved Generative Adversarial Networks.
    authors: <span class="color-blue">Xintong Wang</span>, Jianming Lv
    booktitle: "Proceedings of the 11th International Conference on Knowledge Science, Engineering and Management (<strong>KSEM</strong>)"
    booktitle-url: papers/1806.04533.pdf
    doc-url: papers/1806.04533.pdf
    venue: workshop
    abstract: >
        Person re-identification (Re-ID) aims to match the image frames which contain the same person in the surveillance videos. Most of the Re-ID algorithms conduct supervised training in some small labeled datasets, so directly deploying these trained models to the real-world large camera networks may lead to a poor performance due to underfitting. The significant difference between the source training dataset and the target testing dataset makes it challenging to incrementally optimize the model. To address this challenge, we propose a novel solution by transforming the unlabeled images in the target domain to fit the original classifier by using our proposed similarity preserved generative adversarial networks model, SimPGAN. Specifically, SimPGAN adopts the generative adversarial networks with the cycle consistency constraint to transform the unlabeled images in the target domain to the style of the source domain. Meanwhile, SimPGAN uses the similarity consistency loss, which is measured by a siamese deep convolutional neural network, to preserve the similarity of the transformed images of the same person. Comprehensive experiments based on multiple real surveillance datasets are conducted, and the results show that our algorithm is better than the state-of-the-art cross-dataset unsupervised person Re-ID algorithms.
  - layout: paper
    year: 2016
    paper-type: inproceedings
    img: ICIOT2016
    title: "T-CONV: A Convolutional Neural Network For Multi-scale Taxi Trajectory Prediction"
    authors: Jianming Lv, Qing Li, <span class="color-blue">Xintong Wang</span>, Qinghui Sun
    booktitle: "Proceedings of the 5th IEEE International Conference on Big Data and Smart Computing (<strong>BigComp</strong>)"
    booktitle-url: papers/1611.07635.pdf
    doc-url: papers/1611.07635.pdf
    venue: workshop
    abstract: >
      Precise destination prediction of taxi trajectories can benefit many intelligent location based services such as accurate ad for passengers. Traditional prediction approaches, which treat trajectories as one-dimensional sequences and process them in single scale, fail to capture the diverse two-dimensional patterns of trajectories in different spatial scales. In this paper, we propose T-CONV which models trajectories as two-dimensional images, and adopts multi-layer convolutional neural networks to combine multi-scale trajectory patterns to achieve precise prediction. Furthermore, we conduct gradient analysis to visualize the multi-scale spatial patterns captured by T-CONV and extract the areas with distinct influence on the ultimate prediction. Finally, we integrate multiple local enhancement convolutional fields to explore these important areas deeply for better prediction. Comprehensive experiments based on real trajectory data show that T-CONV can achieve higher accuracy than the state-of-the-art methods.
