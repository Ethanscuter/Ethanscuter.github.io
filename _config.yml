exclude: ['README.md']
timezone: US/Eastern
papers:
  - layout: paper
    year: 2019
    paper-type: inproceedings
    img: IJWSR2017
    title: Fusing External Language Model in Abstractive Summarization.
    authors: <span class="color-blue">Xintong Wang</span>,Wenjie Li
    booktitle: "EMNLP, (CCF B), <strong>Under Review</strong>"
    booktitle-url: papers/1806.04533.pdf
    doc-url: papers/Lv-Wang2018_Chapter_Cross-DatasetPersonRe-identifi.pdf
    venue: workshop
    abstract: >
        Recent sequence-to-sequence neural network models provide a viable new solution to abstractive text summarization, which aims to rewrite a long text into a short and concise form while preserving the most crucial information. However, these models face significant challenges when generating both semantically and syntactically correct summaries. In this work, we explore the potential approaches to incorporate an external (pre-trained) language model to augment the linguistic quality of text generation. This allows the internal (decoder) language model to focus more on jointly learning summary content selection and generation. Fused with the external language model, our abstractive summarization model achieves the results comparable to state-of-the-art models in terms of ROUGE scores, and meanwhile shows significant improvements in both perplexity and human evaluations. 
  - layout: paper
    year: 2019
    paper-type: inproceedings
    img: IJWSR2017
    title: Generative Adversarial Network for Abstractive Text Summarization with Multi-task Constraint.
    authors: Min Yang, <span class="color-blue">Xintong Wang</span>, Yao Lu, Jianming Lv, Qiang Qu
    booktitle: "Information Science, (Q1 Journal)."
    booktitle-url: papers/1806.04533.pdf
    doc-url: papers/Lv-Wang2018_Chapter_Cross-DatasetPersonRe-identifi.pdf
    venue: workshop
    abstract: >
        Recent artificial intelligence studies have witnessed great interests in generating condensed and concise summaries automatically that retain the salient information of a source text, which is known as the abstractive text summarization task. In this paper, we present a Generative Adversarial Network for Abstractive Text Summarization with Multi-Task constraint (GAN-ATSMT). Specifically, GANATSMT utilizes an adversarial framework to jointly train a generative model G and a discriminative model D. The generative model G employs the sequence-to-sequence architecture as its backbone, taking the original text as input and generate the summary. We employ a convolutional neural network (CNN) classifier as the discriminative model D, which attempts to distinguish the generated summaries from the ground truth summaries. The generator G and the discriminator D are optimized with a minimax two-player game. Thus, this adversarial process can eventually adjust G to generate plausible and high-quality summaries. Furthermore, we additionally propose extended regularizations for the generative model G using the multi-task learning, sharing its LSTM encoder and LSTM decoder with the text categorization task and the syntax annotation task, respectively. The auxiliary tasks help to improve the quality of locating salient information of a document and generate high-quality summaries from language modeling perspective alleviating the issues of incomplete sentences and duplicated words. We conduct extensive experiments to estimate the effectiveness of GAN-ATSMT model on two real-life datasets. Experimental results illustrate that GAN-ATSMT is able to achieve better performance than the state-of-the-art abstractive text summarization methods in terms of the quantitative evaluation metrics (i.e., ROUGE and human evaluation) and qualitative evaluation.
  - layout: paper
    year: 2018
    paper-type: inproceedings
    img: IJWSR2017
    title: Cross-dataset Person Re-Identification Using Similarity Preserved Generative Adversarial Networks.
    authors: <span class="color-blue">Xintong Wang</span>, Jianming Lv
    booktitle: "Proceedings of the 11th International Conference on Knowledge Science, Engineering and Management (<strong>KSEM</strong>), (CCF C)"
    booktitle-url: papers/1806.04533.pdf
    doc-url: papers/Lv-Wang2018_Chapter_Cross-DatasetPersonRe-identifi.pdf
    venue: workshop
    abstract: >
        Person re-identification (Re-ID) aims to match the image frames which contain the same person in the surveillance videos. Most of the Re-ID algorithms conduct supervised training in some small labeled datasets, so directly deploying these trained models to the real-world large camera networks may lead to a poor performance due to underfitting. The significant difference between the source training dataset and the target testing dataset makes it challenging to incrementally optimize the model. To address this challenge, we propose a novel solution by transforming the unlabeled images in the target domain to fit the original classifier by using our proposed similarity preserved generative adversarial networks model, SimPGAN. Specifically, SimPGAN adopts the generative adversarial networks with the cycle consistency constraint to transform the unlabeled images in the target domain to the style of the source domain. Meanwhile, SimPGAN uses the similarity consistency loss, which is measured by a siamese deep convolutional neural network, to preserve the similarity of the transformed images of the same person. Comprehensive experiments based on multiple real surveillance datasets are conducted, and the results show that our algorithm is better than the state-of-the-art cross-dataset unsupervised person Re-ID algorithms.
  - layout: paper
    year: 2018
    paper-type: inproceedings
    img: ICIOT2016
    title: "T-CONV: A Convolutional Neural Network For Multi-scale Taxi Trajectory Prediction"
    authors: Jianming Lv, Qing Li, <span class="color-blue">Xintong Wang</span>, Qinghui Sun
    booktitle: "Proceedings of the 5th IEEE International Conference on Big Data and Smart Computing (<strong>BigComp</strong>)"
    booktitle-url: papers/1611.07635.pdf
    doc-url: papers/1611.07635.pdf
    venue: workshop
    abstract: >
      Precise destination prediction of taxi trajectories can benefit many intelligent location based services such as accurate ad for passengers. Traditional prediction approaches, which treat trajectories as one-dimensional sequences and process them in single scale, fail to capture the diverse two-dimensional patterns of trajectories in different spatial scales. In this paper, we propose T-CONV which models trajectories as two-dimensional images, and adopts multi-layer convolutional neural networks to combine multi-scale trajectory patterns to achieve precise prediction. Furthermore, we conduct gradient analysis to visualize the multi-scale spatial patterns captured by T-CONV and extract the areas with distinct influence on the ultimate prediction. Finally, we integrate multiple local enhancement convolutional fields to explore these important areas deeply for better prediction. Comprehensive experiments based on real trajectory data show that T-CONV can achieve higher accuracy than the state-of-the-art methods.
  - layout: paper
    year: 2017
    paper-type: inproceedings
    img: IJWSR2017
    title: "Regression Approach for Optimal Purchase of Hosts Cluster in Fixed Fund for Hadoop Big-data Platform"
    authors: Haitao Yang, Jianming Lv, Fei Xu, <span class="color-blue">Xintong Wang</span>, Yilin Huang, Lanting Xia
    booktitle: "Proceedings of the 19th International Conference on Smart City, Transportation and Buildings (<strong>ICSCTB</strong>)"
    booktitle-url: papers/Regression-Approach-for-Optimal-Purchase-of-Hosts-Cluster-in-Fixed-Fund-for-Hadoop-Big-Data-Platform.pdf
    doc-url: papers/Regression-Approach-for-Optimal-Purchase-of-Hosts-Cluster-in-Fixed-Fund-for-Hadoop-Big-Data-Platform.pdf
    venue: workshop
    abstract: >
      Given a fixed fund, purchasing fewer hosts of higher capability or inversely more of lower capability is a must-be-made trade-off in practices for building a Hadoop big data platform. An exploratory study is presented for a Housing Big Data Platform project (HBDP), where typical big data computing is with SQL queries of aggregate, join, and space-time condition selections executed upon massive data from more than 10 million housing units. In HBDP, an empirical formula was introduced to predict the performance of host clusters potential for the intended typical big data computing, and it was shaped via a regression approach. With this empirical formula, it is easy to suggest an optimal cluster configuration. The investigation was based on a typical Hadoop computing ecosystem HDFS+Hive+Spark. A proper metric was raised to measure the performance of Hadoop clusters in HBDP, which was tested and compared with its predicted counterpart, on executing three kinds of typical SQL query tasks. Tests were conducted with respect to factors of CPU benchmark, memory size, virtual host division, and the number of element physical host in cluster. The research has been applied to practical cluster procurement for housing big data computing.
  - layout: paper
    year: 2016
    paper-type: inproceedings
    img: ICIOT2016
    title: "TREST: A Hadoop Based Distributed Mobile Trajectory Retrieval System"
    authors: Jianming Lv, <span class="color-blue">Xintong Wang</span>, Fengtao Huang, Junjie Yang
    booktitle: "Proceedings of the 1st IEEE International Conference on Data Science in Cyberspace (<strong>DSC</strong>)"
    booktitle-url: papers/07866148.pdf
    doc-url: papers/07866148.pdf
    venue: workshop
    abstract: >
      Nowadays, mobile phones have prevailed in a great variety of applications, through which massive personal trajectories can be collected and analyzed to support many interesting location-based services. However, it is still challenging to efficiently store and retrieve this kind of spatio-temporal data, which has typical big-data feature with large size, streaming style and multiple data source. To address this issue, we develop a mobile trajectory retrieval system named TREST, which is based on the distributed Hadoop and HBase systems. TREST makes use of the horizontal expansion mechanism of Hadoop to store overwhelming spatio-temporal trajectories, and supports frequent incremental insertion of data stream. Meanwhile, TREST maps the spatio-temporal features of trajectories into the simple key-value schema of HBase to support fast retrieval. We also develop a prototype of TREST to manipulate the real mobile trajectory data set, which contains totally 104 million records collected by mobile service providers. Experiments on this data set show that TREST can efficiently support both Single-track and All-track retrieval within milliseconds on average.
  - layout: paper
    year: 2014
    paper-type: inproceedings
    img: IJWSR2017
    title: "GPS Trajectory Mining: a Survey"
    authors: Haibiao Lin, Jianming Lv, Can Yang, Miaoyi Deng, Kaitao Wang, <span class="color-blue">Xintong Wang</span>
    booktitle: "Journal of Computational Information Systems Volume 16, Issue 10 (<strong>JCIS</strong>)"
    booktitle-url: papers/GPS_Trajectory_Mining_a_Survey.pdf
    doc-url: papers/GPS_Trajectory_Mining_a_Survey.pdf
    venue: workshop
    abstract: >
        Growing demand of computational power brings increasing scale and complexity of cloud datacenters.
        However, such increase also generates growing energy consumption and related cost incurred for cooling
        and maintenance. With concerns of cost and energy saving by both industry and academy, the reduction of
        energy consumption of cloud datacenters becomes a hotspot issue. Recently, virtual-machine-consolidationbased
        strategies are proposed as promising methods for reduction of cloud energy consumption. Virtual
        machine (VM) consolidation effectively increases the resource utilization rate. However, it remains a
        great challenge how to reduce energy consumption while maintaining the quality of service (QoS) at a
        satisfactory level. In this work, a comprehensive framework is presented for the above-mentioned problem,
        which aims at maximizing the number of physical machines (PMs) to be turned off within a consolidation
        period following the constraints of QoS, in terms of Service-Level-Agreement (SLA) violation rate. In
        comparison with most existing related works which consider invariant utilization rate of PMs in computing
        energy reduction of candidate migration plans, propose framework considers time-varying utilization rate
        and employs the number of PMs to be turned off within a consolidation period (NPTCP for simple) as
        the optimization objective. The proposed framework consists of a resource selection algorithm taking the
        predicted migration overhead (derived by the Pareto distribution) as inputs and another algorithm generating
        optimal matching plans based on preference scores of candidate VMs. For the model validation purpose,
        a case study is conducted on the CloudSim simulation platform and it shows that the proposed method
        achieves better energy reduction and less SLA violation.

